{"-k --content-disposition -S http://localhost/corpus/alien_build_plugin_fetch_wget/dir/foo-1.01.tar":{"stderr":"--2021-05-12 00:10:35--  http://localhost/corpus/alien_build_plugin_fetch_wget/dir/foo-1.01.tar\nResolving localhost (localhost)... ::1, 127.0.0.1\nConnecting to localhost (localhost)|::1|:42643... failed: Connection refused.\nConnecting to localhost (localhost)|127.0.0.1|:42643... connected.\nHTTP request sent, awaiting response... \n  HTTP/1.0 200 OK\n  Date: Wed, 12 May 2021 06:10:35 GMT\n  Server: HTTP::Server::PSGI\n  Content-Type: application/x-tar\n  Content-Length: 17\n  Last-Modified: Sun, 02 May 2021 15:41:03 GMT\nLength: 17 [application/x-tar]\nSaving to: âfoo-1.01.tarâ\n\n     0K                                                       100% 1.65M=0s\n\n2021-05-12 00:10:35 (1.65 MB/s) - âfoo-1.01.tarâ saved [17/17]\n\nConverted links in 0 files in 0 seconds.\n","exit":0,"files":{"foo-1.01.tar":"content:foo-1.01\n"},"stdout":""},"-k --content-disposition -S http://localhost/corpus/alien_build_plugin_fetch_wget/dir/bogus.html":{"files":{},"exit":8,"stdout":"","stderr":"--2021-05-12 00:10:35--  http://localhost/corpus/alien_build_plugin_fetch_wget/dir/bogus.html\nResolving localhost (localhost)... ::1, 127.0.0.1\nConnecting to localhost (localhost)|::1|:42643... failed: Connection refused.\nConnecting to localhost (localhost)|127.0.0.1|:42643... connected.\nHTTP request sent, awaiting response... \n  HTTP/1.0 404 Not Found\n  Date: Wed, 12 May 2021 06:10:35 GMT\n  Server: HTTP::Server::PSGI\n  Content-Type: text/plain\n  Content-Length: 9\n2021-05-12 00:10:35 ERROR 404: Not Found.\n\nConverted links in 0 files in 0 seconds.\n"},"--help":{"stderr":"","stdout":"GNU Wget 1.20.1, a non-interactive network retriever.\nUsage: wget [OPTION]... [URL]...\n\nMandatory arguments to long options are mandatory for short options too.\n\nStartup:\n  -V,  --version                   display the version of Wget and exit\n  -h,  --help                      print this help\n  -b,  --background                go to background after startup\n  -e,  --execute=COMMAND           execute a `.wgetrc'-style command\n\nLogging and input file:\n  -o,  --output-file=FILE          log messages to FILE\n  -a,  --append-output=FILE        append messages to FILE\n  -d,  --debug                     print lots of debugging information\n  -q,  --quiet                     quiet (no output)\n  -v,  --verbose                   be verbose (this is the default)\n  -nv, --no-verbose                turn off verboseness, without being quiet\n       --report-speed=TYPE         output bandwidth as TYPE.  TYPE can be bits\n  -i,  --input-file=FILE           download URLs found in local or external FILE\n  -F,  --force-html                treat input file as HTML\n  -B,  --base=URL                  resolves HTML input-file links (-i -F)\n                                     relative to URL\n       --config=FILE               specify config file to use\n       --no-config                 do not read any config file\n       --rejected-log=FILE         log reasons for URL rejection to FILE\n\nDownload:\n  -t,  --tries=NUMBER              set number of retries to NUMBER (0 unlimits)\n       --retry-connrefused         retry even if connection is refused\n       --retry-on-http-error=ERRORS    comma-separated list of HTTP errors to retry\n  -O,  --output-document=FILE      write documents to FILE\n  -nc, --no-clobber                skip downloads that would download to\n                                     existing files (overwriting them)\n       --no-netrc                  don't try to obtain credentials from .netrc\n  -c,  --continue                  resume getting a partially-downloaded file\n       --start-pos=OFFSET          start downloading from zero-based position OFFSET\n       --progress=TYPE             select progress gauge type\n       --show-progress             display the progress bar in any verbosity mode\n  -N,  --timestamping              don't re-retrieve files unless newer than\n                                     local\n       --no-if-modified-since      don't use conditional if-modified-since get\n                                     requests in timestamping mode\n       --no-use-server-timestamps  don't set the local file's timestamp by\n                                     the one on the server\n  -S,  --server-response           print server response\n       --spider                    don't download anything\n  -T,  --timeout=SECONDS           set all timeout values to SECONDS\n       --dns-timeout=SECS          set the DNS lookup timeout to SECS\n       --connect-timeout=SECS      set the connect timeout to SECS\n       --read-timeout=SECS         set the read timeout to SECS\n  -w,  --wait=SECONDS              wait SECONDS between retrievals\n       --waitretry=SECONDS         wait 1..SECONDS between retries of a retrieval\n       --random-wait               wait from 0.5*WAIT...1.5*WAIT secs between retrievals\n       --no-proxy                  explicitly turn off proxy\n  -Q,  --quota=NUMBER              set retrieval quota to NUMBER\n       --bind-address=ADDRESS      bind to ADDRESS (hostname or IP) on local host\n       --limit-rate=RATE           limit download rate to RATE\n       --no-dns-cache              disable caching DNS lookups\n       --restrict-file-names=OS    restrict chars in file names to ones OS allows\n       --ignore-case               ignore case when matching files/directories\n  -4,  --inet4-only                connect only to IPv4 addresses\n  -6,  --inet6-only                connect only to IPv6 addresses\n       --prefer-family=FAMILY      connect first to addresses of specified family,\n                                     one of IPv6, IPv4, or none\n       --user=USER                 set both ftp and http user to USER\n       --password=PASS             set both ftp and http password to PASS\n       --ask-password              prompt for passwords\n       --use-askpass=COMMAND       specify credential handler for requesting \n                                     username and password.  If no COMMAND is \n                                     specified the WGET_ASKPASS or the SSH_ASKPASS \n                                     environment variable is used.\n       --no-iri                    turn off IRI support\n       --local-encoding=ENC        use ENC as the local encoding for IRIs\n       --remote-encoding=ENC       use ENC as the default remote encoding\n       --unlink                    remove file before clobber\n       --xattr                     turn on storage of metadata in extended file attributes\n\nDirectories:\n  -nd, --no-directories            don't create directories\n  -x,  --force-directories         force creation of directories\n  -nH, --no-host-directories       don't create host directories\n       --protocol-directories      use protocol name in directories\n  -P,  --directory-prefix=PREFIX   save files to PREFIX/..\n       --cut-dirs=NUMBER           ignore NUMBER remote directory components\n\nHTTP options:\n       --http-user=USER            set http user to USER\n       --http-password=PASS        set http password to PASS\n       --no-cache                  disallow server-cached data\n       --default-page=NAME         change the default page name (normally\n                                     this is 'index.html'.)\n  -E,  --adjust-extension          save HTML/CSS documents with proper extensions\n       --ignore-length             ignore 'Content-Length' header field\n       --header=STRING             insert STRING among the headers\n       --compression=TYPE          choose compression, one of auto, gzip and none. (default: none)\n       --max-redirect              maximum redirections allowed per page\n       --proxy-user=USER           set USER as proxy username\n       --proxy-password=PASS       set PASS as proxy password\n       --referer=URL               include 'Referer: URL' header in HTTP request\n       --save-headers              save the HTTP headers to file\n  -U,  --user-agent=AGENT          identify as AGENT instead of Wget/VERSION\n       --no-http-keep-alive        disable HTTP keep-alive (persistent connections)\n       --no-cookies                don't use cookies\n       --load-cookies=FILE         load cookies from FILE before session\n       --save-cookies=FILE         save cookies to FILE after session\n       --keep-session-cookies      load and save session (non-permanent) cookies\n       --post-data=STRING          use the POST method; send STRING as the data\n       --post-file=FILE            use the POST method; send contents of FILE\n       --method=HTTPMethod         use method \"HTTPMethod\" in the request\n       --body-data=STRING          send STRING as data. --method MUST be set\n       --body-file=FILE            send contents of FILE. --method MUST be set\n       --content-disposition       honor the Content-Disposition header when\n                                     choosing local file names (EXPERIMENTAL)\n       --content-on-error          output the received content on server errors\n       --auth-no-challenge         send Basic HTTP authentication information\n                                     without first waiting for the server's\n                                     challenge\n\nHTTPS (SSL/TLS) options:\n       --secure-protocol=PR        choose secure protocol, one of auto, SSLv2,\n                                     SSLv3, TLSv1, TLSv1_1, TLSv1_2 and PFS\n       --https-only                only follow secure HTTPS links\n       --no-check-certificate      don't validate the server's certificate\n       --certificate=FILE          client certificate file\n       --certificate-type=TYPE     client certificate type, PEM or DER\n       --private-key=FILE          private key file\n       --private-key-type=TYPE     private key type, PEM or DER\n       --ca-certificate=FILE       file with the bundle of CAs\n       --ca-directory=DIR          directory where hash list of CAs is stored\n       --crl-file=FILE             file with bundle of CRLs\n       --pinnedpubkey=FILE/HASHES  Public key (PEM/DER) file, or any number\n                                   of base64 encoded sha256 hashes preceded by\n                                   'sha256//' and separated by ';', to verify\n                                   peer against\n\n       --ciphers=STR           Set the priority string (GnuTLS) or cipher list string (OpenSSL) directly.\n                                   Use with care. This option overrides --secure-protocol.\n                                   The format and syntax of this string depend on the specific SSL/TLS engine.\nHSTS options:\n       --no-hsts                   disable HSTS\n       --hsts-file                 path of HSTS database (will override default)\n\nFTP options:\n       --ftp-user=USER             set ftp user to USER\n       --ftp-password=PASS         set ftp password to PASS\n       --no-remove-listing         don't remove '.listing' files\n       --no-glob                   turn off FTP file name globbing\n       --no-passive-ftp            disable the \"passive\" transfer mode\n       --preserve-permissions      preserve remote file permissions\n       --retr-symlinks             when recursing, get linked-to files (not dir)\n\nFTPS options:\n       --ftps-implicit                 use implicit FTPS (default port is 990)\n       --ftps-resume-ssl               resume the SSL/TLS session started in the control connection when\n                                         opening a data connection\n       --ftps-clear-data-connection    cipher the control channel only; all the data will be in plaintext\n       --ftps-fallback-to-ftp          fall back to FTP if FTPS is not supported in the target server\nWARC options:\n       --warc-file=FILENAME        save request/response data to a .warc.gz file\n       --warc-header=STRING        insert STRING into the warcinfo record\n       --warc-max-size=NUMBER      set maximum size of WARC files to NUMBER\n       --warc-cdx                  write CDX index files\n       --warc-dedup=FILENAME       do not store records listed in this CDX file\n       --no-warc-compression       do not compress WARC files with GZIP\n       --no-warc-digests           do not calculate SHA1 digests\n       --no-warc-keep-log          do not store the log file in a WARC record\n       --warc-tempdir=DIRECTORY    location for temporary files created by the\n                                     WARC writer\n\nRecursive download:\n  -r,  --recursive                 specify recursive download\n  -l,  --level=NUMBER              maximum recursion depth (inf or 0 for infinite)\n       --delete-after              delete files locally after downloading them\n  -k,  --convert-links             make links in downloaded HTML or CSS point to\n                                     local files\n       --convert-file-only         convert the file part of the URLs only (usually known as the basename)\n       --backups=N                 before writing file X, rotate up to N backup files\n  -K,  --backup-converted          before converting file X, back up as X.orig\n  -m,  --mirror                    shortcut for -N -r -l inf --no-remove-listing\n  -p,  --page-requisites           get all images, etc. needed to display HTML page\n       --strict-comments           turn on strict (SGML) handling of HTML comments\n\nRecursive accept/reject:\n  -A,  --accept=LIST               comma-separated list of accepted extensions\n  -R,  --reject=LIST               comma-separated list of rejected extensions\n       --accept-regex=REGEX        regex matching accepted URLs\n       --reject-regex=REGEX        regex matching rejected URLs\n       --regex-type=TYPE           regex type (posix|pcre)\n  -D,  --domains=LIST              comma-separated list of accepted domains\n       --exclude-domains=LIST      comma-separated list of rejected domains\n       --follow-ftp                follow FTP links from HTML documents\n       --follow-tags=LIST          comma-separated list of followed HTML tags\n       --ignore-tags=LIST          comma-separated list of ignored HTML tags\n  -H,  --span-hosts                go to foreign hosts when recursive\n  -L,  --relative                  follow relative links only\n  -I,  --include-directories=LIST  list of allowed directories\n       --trust-server-names        use the name specified by the redirection\n                                     URL's last component\n  -X,  --exclude-directories=LIST  list of excluded directories\n  -np, --no-parent                 don't ascend to the parent directory\n\nEmail bug reports, questions, discussions to <bug-wget@gnu.org>\nand/or open issues at https://savannah.gnu.org/bugs/?func=additem&group=wget.\n","files":{},"exit":0},"-k --content-disposition -S http://localhost/corpus/alien_build_plugin_fetch_wget/dir/html_test.html":{"files":{"html_test.html":"<html><head><title>Hello World</title></head><body><p>Hello World</p></body></html>\n"},"exit":0,"stdout":"","stderr":"--2021-05-12 00:10:35--  http://localhost/corpus/alien_build_plugin_fetch_wget/dir/html_test.html\nResolving localhost (localhost)... ::1, 127.0.0.1\nConnecting to localhost (localhost)|::1|:42643... failed: Connection refused.\nConnecting to localhost (localhost)|127.0.0.1|:42643... connected.\nHTTP request sent, awaiting response... \n  HTTP/1.0 200 OK\n  Date: Wed, 12 May 2021 06:10:35 GMT\n  Server: HTTP::Server::PSGI\n  Content-Type: text/html; charset=utf-8\n  Content-Length: 84\n  Last-Modified: Wed, 12 May 2021 04:39:27 GMT\nLength: 84 [text/html]\nSaving to: âhtml_test.htmlâ\n\n     0K                                                       100% 9.79M=0s\n\n2021-05-12 00:10:35 (9.79 MB/s) - âhtml_test.htmlâ saved [84/84]\n\nConverting links in html_test.html... nothing to do.\nConverted links in 1 files in 0 seconds.\n"}}